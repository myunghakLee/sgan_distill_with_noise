{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596fde5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:05.639275Z",
     "start_time": "2023-01-27T18:19:03.896168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cuda_11_6/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "from attrdict import AttrDict\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from sgan.losses import displacement_error, final_displacement_error\n",
    "from sgan.losses import gan_g_loss, gan_d_loss, l2_loss\n",
    "\n",
    "from sgan.utils import int_tuple, bool_flag, get_total_norm\n",
    "from sgan.utils import relative_to_abs, get_dset_path\n",
    "\n",
    "from sgan.models import TrajectoryGenerator, TrajectoryDiscriminator\n",
    "from sgan.data.loader import data_loader\n",
    "\n",
    "import train\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cf1be",
   "metadata": {},
   "source": [
    "# Modle Load\n",
    "\n",
    "hotel_8_model.pt : hotel이 아닌 다른 데이터로 학습하고 hotel에서 테스트할 모델. 예측 길이는 8\n",
    "\n",
    "Distillation에서는 일반적으로 generator만 학습하므로 우선 generator만 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde95beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:05.652424Z",
     "start_time": "2023-01-27T18:19:05.642631Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    generator = TrajectoryGenerator(\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        encoder_h_dim=args.encoder_h_dim_g,\n",
    "        decoder_h_dim=args.decoder_h_dim_g,\n",
    "        mlp_dim=args.mlp_dim,\n",
    "        num_layers=args.num_layers,\n",
    "        noise_dim=args.noise_dim,\n",
    "        noise_type=args.noise_type,\n",
    "        noise_mix_type=args.noise_mix_type,\n",
    "        pooling_type=args.pooling_type,\n",
    "        pool_every_timestep=args.pool_every_timestep,\n",
    "        dropout=args.dropout,\n",
    "        bottleneck_dim=args.bottleneck_dim,\n",
    "        neighborhood_size=args.neighborhood_size,\n",
    "        grid_size=args.grid_size,\n",
    "        batch_norm=args.batch_norm)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    generator.cuda()\n",
    "    generator.train()\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def get_discriminator(args):\n",
    "    discriminator = TrajectoryDiscriminator(\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        h_dim=args.encoder_h_dim_d,\n",
    "        mlp_dim=args.mlp_dim,\n",
    "        num_layers=args.num_layers,\n",
    "        dropout=args.dropout,\n",
    "        batch_norm=args.batch_norm,\n",
    "        d_type='local')\n",
    "#         activation='leakyrelu')\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19c684c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:05.676542Z",
     "start_time": "2023-01-27T18:19:05.656102Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        \n",
    "def get_dtypes(args):\n",
    "    long_dtype = torch.LongTensor\n",
    "    float_dtype = torch.FloatTensor\n",
    "    if args.use_gpu == 1:\n",
    "        long_dtype = torch.cuda.LongTensor\n",
    "        float_dtype = torch.cuda.FloatTensor\n",
    "    return long_dtype, float_dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f6565a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:17.620355Z",
     "start_time": "2023-01-27T18:19:08.186791Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./models/sgan-p-models/hotel_8_model.pt\")\n",
    "args = AttrDict(checkpoint['args'])\n",
    "args.output_dir = \"./\"\n",
    "long_dtype, float_dtype = get_dtypes(args)\n",
    "\n",
    "generator_T = get_generator(args)\n",
    "generator_T.load_state_dict(checkpoint['g_state'])\n",
    "\n",
    "generator_S = get_generator(args)\n",
    "generator_S.apply(init_weights)\n",
    "generator_S.type(float_dtype).train()\n",
    "\n",
    "discriminator_S = get_discriminator(args)\n",
    "discriminator_S.apply(init_weights)\n",
    "discriminator_S.type(float_dtype).train()\n",
    "\n",
    "g_loss_fn = gan_g_loss\n",
    "d_loss_fn = gan_d_loss\n",
    "\n",
    "optimizer_g = optim.Adam(generator_S.parameters(), lr=args.g_learning_rate)\n",
    "optimizer_d = optim.Adam(\n",
    "    discriminator_S.parameters(), lr=args.d_learning_rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5852e",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b9e685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:40.111608Z",
     "start_time": "2023-01-27T18:19:23.448527Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = get_dset_path('hotel', 'train')\n",
    "_, train_loader = data_loader(args, train_path)\n",
    "\n",
    "val_path = get_dset_path('hotel', 'val')\n",
    "_, val_loader = data_loader(args, val_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccddf02",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "\n",
    "\n",
    "원본 코드의 학습 구조가 조금 이상하게 되어 있음\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "while(t < args.num_iterations):\n",
    "    d_steps_left = args.d_steps\n",
    "    g_steps_left = args.g_steps\n",
    "    for batch in train_loader:\n",
    "        if d_steps_left > 0:\n",
    "            Train discriminator\n",
    "            d_steps_left -=1\n",
    "           \n",
    "        elif g_steps_left > 0:        \n",
    "            Train generator\n",
    "            g_steps_left -=1\n",
    "        \n",
    "        if d_steps_left > 0 or g_steps_left > 0:\n",
    "            continue\n",
    "        \n",
    "        if t % args.checkpoint_every == 0:\n",
    "            evaluate with val_loader\n",
    "            save model\n",
    "\n",
    "        t += 1\n",
    "        d_steps_left = args.d_steps\n",
    "        g_steps_left = args.g_steps            \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa385aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:41.353838Z",
     "start_time": "2023-01-27T18:19:41.341892Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def discriminator_step(args, batch, generator, discriminator, d_loss_fn, optimizer_d):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "\n",
    "    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "    pred_traj_fake_rel = generator_out\n",
    "    pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "    traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "    traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "    \n",
    "    # Compute loss with optional gradient penalty\n",
    "    data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "    losses['D_data_loss'] = data_loss.item()\n",
    "    loss += data_loss\n",
    "    losses['D_total_loss'] = loss.item()\n",
    "    \n",
    "    \n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_d > 0:\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(),\n",
    "                                 args.clipping_threshold_d)\n",
    "        \n",
    "    optimizer_d.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe23fd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:41.931529Z",
     "start_time": "2023-01-27T18:19:41.924224Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'args': args.__dict__,\n",
    "    'G_losses': defaultdict(list),\n",
    "    'D_losses': defaultdict(list),\n",
    "    'losses_ts': [],\n",
    "    'metrics_val': defaultdict(list),\n",
    "    'metrics_train': defaultdict(list),\n",
    "    'sample_ts': [],\n",
    "    'restore_ts': [],\n",
    "    'norm_g': [],\n",
    "    'norm_d': [],\n",
    "    'counters': {\n",
    "        't': None,\n",
    "        'epoch': None,\n",
    "    },\n",
    "    'g_state': None,\n",
    "    'g_optim_state': None,\n",
    "    'd_state': None,\n",
    "    'd_optim_state': None,\n",
    "    'g_best_state': None,\n",
    "    'd_best_state': None,\n",
    "    'best_t': None,\n",
    "    'g_best_nl_state': None,\n",
    "    'd_best_state_nl': None,\n",
    "    'best_t_nl': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f14aa0",
   "metadata": {},
   "source": [
    "#### alpha = 390, negative = 1일 때 LRP의 obs_traj에 대한 perturbation의 abs의 평균, 평균, std는 각각 다음과 같다.\n",
    "\n",
    "* abs의 평균 : 0.0118972\n",
    "\n",
    "* 평균 : 0.0000887874915\n",
    "\n",
    "* std : 0.065657713\n",
    "\n",
    "#### alpha = 390, negative = 1일 때 LRP의 obs_traj_rel에 대한 perturbation의 abs의 평균, 평균, std는 각각 다음과 같다.\n",
    "\n",
    "* abs의 평균 : 0.0064371\n",
    "\n",
    "* 평균 : 0.0000498725123\n",
    "\n",
    "* std : 0.0324582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63c92b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:42.901278Z",
     "start_time": "2023-01-27T18:19:42.875414Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generator_step(args, batch, generator_S, generator_T, discriminator, g_loss_fn, optimizer_g, mode):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    \n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_l2_loss_rel = []\n",
    "    g_distill_loss = []\n",
    "    \n",
    "    \n",
    "    loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "    for _ in range(args.best_k):\n",
    "        generator_out_S, feat_S = generator_S(obs_traj, obs_traj_rel, seq_start_end, is_feat=True)\n",
    "        \n",
    "        if mode == 'lrp':\n",
    "            obs_traj_ref, obs_traj_rel_ref = get_lrp(generator_T, obs_traj, obs_traj_rel, pred_traj_gt_rel, seq_start_end)\n",
    "        elif mode == 'random_noise':\n",
    "            obs_traj_ref = obs_traj + (torch.randn_like(obs_traj) * 0.0656)\n",
    "            obs_traj_rel_ref = obs_traj_rel + (torch.randn_like(obs_traj_rel) * 0.0324)\n",
    "            \n",
    "        generator_out_T, feat_T = generator_T(obs_traj_ref, obs_traj_rel_ref, seq_start_end, is_feat=True)\n",
    "#         generator_out_S2, feat_S2 = generator_S(obs_traj_ref, obs_traj_rel_ref, seq_start_end, is_feat=True)\n",
    "\n",
    "        pred_traj_fake_rel_S = generator_out_S\n",
    "        pred_traj_fake_rel_T = generator_out_T\n",
    "\n",
    "        pred_traj_fake_S = relative_to_abs(pred_traj_fake_rel_S, obs_traj[-1])\n",
    "        pred_traj_fake_T = relative_to_abs(pred_traj_fake_rel_T, obs_traj[-1])\n",
    "\n",
    "        if args.l2_loss_weight > 0:\n",
    "            g_l2_loss_rel.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel_S,\n",
    "                pred_traj_gt_rel,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "            \n",
    "            g_distill_loss.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel_S,\n",
    "                pred_traj_fake_rel_T,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "            \n",
    "            \n",
    "    g_l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_distill_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    if args.l2_loss_weight > 0:\n",
    "        g_l2_loss_rel = torch.stack(g_l2_loss_rel, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_l2_loss_rel = g_l2_loss_rel[start:end]\n",
    "            _g_l2_loss_rel = torch.sum(_g_l2_loss_rel, dim=0)\n",
    "            _g_l2_loss_rel = torch.min(_g_l2_loss_rel) / torch.sum(loss_mask[start:end])\n",
    "            g_l2_loss_sum_rel += _g_l2_loss_rel\n",
    "            \n",
    "        losses['G_l2_loss_rel'] = g_l2_loss_sum_rel.item()\n",
    "        loss += g_l2_loss_sum_rel\n",
    "\n",
    "        \n",
    "        g_distill_loss = torch.stack(g_distill_loss, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_distill_loss = g_l2_loss_rel[start:end]\n",
    "            _g_distill_loss = torch.sum(_g_distill_loss, dim=0)\n",
    "            _g_distill_loss = torch.min(_g_distill_loss) / torch.sum(loss_mask[start:end])\n",
    "            g_distill_loss_sum_rel += _g_distill_loss\n",
    "            \n",
    "        losses['g_distill_loss'] = g_distill_loss_sum_rel.item()\n",
    "        loss += g_distill_loss_sum_rel\n",
    "        \n",
    "        loss_feat = 0\n",
    "        for i in range(len(feat_S)):\n",
    "            if isinstance(feat_S[i], tuple):\n",
    "                for j in range(len(feat_S[i])):\n",
    "                    loss_feat += torch.mean((feat_S[i][j] - feat_T[i][j]) ** 2)\n",
    "            else:\n",
    "                loss_feat += torch.mean((feat_S[i] - feat_T[i]) ** 2)\n",
    "                \n",
    "        losses['loss_feat'] = loss_feat.item()\n",
    "        loss += loss_feat\n",
    "        \n",
    "        \n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake_S], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel_S], dim=0)\n",
    "    \n",
    "    if discriminator != None:\n",
    "        scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "        discriminator_loss = g_loss_fn(scores_fake)\n",
    "        loss += discriminator_loss\n",
    "        losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "        losses['G_total_loss'] = loss.item()\n",
    "    else:\n",
    "        discriminator_loss = 0\n",
    "    \n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_g > 0:\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            generator_S.parameters(), args.clipping_threshold_g\n",
    "        )\n",
    "    optimizer_g.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346017af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:44.014121Z",
     "start_time": "2023-01-27T18:19:44.006965Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_lrp(generator_T, obs_traj, obs_traj_rel, pred_traj_gt_rel, seq_start_end, alpha = 390, negative = 1):\n",
    "    generator_T.train()\n",
    "    \n",
    "    obs_traj.requires_grad = True\n",
    "    obs_traj_rel.requires_grad = True\n",
    "    \n",
    "    pred = generator_T(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "    loss = torch.mean((pred - pred_traj_gt_rel) ** 2)\n",
    "    loss.backward()\n",
    "\n",
    "    #  ===================================================================\n",
    "    obs_traj_lrp = obs_traj - (obs_traj.grad * torch.abs(obs_traj) * alpha * negative)\n",
    "    obs_traj_rel_lrp = obs_traj_rel - (obs_traj_rel.grad * torch.abs(obs_traj_rel) * alpha * negative)\n",
    "\n",
    "    return obs_traj_lrp, obs_traj_rel_lrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdf1b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:44.367277Z",
     "start_time": "2023-01-27T18:19:44.345382Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def main(args):\n",
    "    t = 0\n",
    "    epoch = 0\n",
    "    while t < args.num_iterations:\n",
    "        gc.collect()\n",
    "        d_steps_left = args.d_steps\n",
    "        g_steps_left = args.g_steps\n",
    "        epoch += 1\n",
    "\n",
    "        pbar = tqdm(train_loader)\n",
    "        for batch in pbar:\n",
    "\n",
    "            if d_steps_left > 0:\n",
    "                step_type = 'd'\n",
    "                losses_d = discriminator_step(args, batch, generator_S,\n",
    "                                              discriminator_S, d_loss_fn,\n",
    "                                              optimizer_d)\n",
    "                d_steps_left -= 1\n",
    "            elif g_steps_left > 0:\n",
    "                step_type = 'g'\n",
    "                losses_g = generator_step(args, batch, generator_S, generator_T,\n",
    "                                          discriminator_S, g_loss_fn,\n",
    "                                          optimizer_g, mode = \"random_noise\")\n",
    "                g_steps_left -= 1\n",
    "\n",
    "            # 여기 밑으로는 그냥 evaluation하고 모델 저장하는 부분\n",
    "            if d_steps_left > 0 or g_steps_left > 0:\n",
    "                continue\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"G_l2\" : losses_g['G_l2_loss_rel'],\n",
    "                \"G_adv\" : losses_g['G_discriminator_loss'],\n",
    "                \"G_distill\" : losses_g['g_distill_loss'],\n",
    "                \"G_feat\" : losses_g['loss_feat'],\n",
    "                \"D\" : losses_d['D_total_loss']\n",
    "            })\n",
    "\n",
    "            # Maybe save a checkpoint\n",
    "            if t > 0 and t % args.checkpoint_every == 0:\n",
    "    #         if True:\n",
    "                print('Checking stats on val ...')\n",
    "                metrics_val = train.check_accuracy(\n",
    "                    args, val_loader, generator_S, discriminator_S, d_loss_fn\n",
    "                )\n",
    "                print('Checking stats on train ...')\n",
    "                metrics_train = train.check_accuracy(\n",
    "                    args, train_loader, generator_S, discriminator_S,\n",
    "                    d_loss_fn, limit=True\n",
    "                )\n",
    "\n",
    "                for k, v in sorted(metrics_val.items()):\n",
    "                    print('  [val] {}: {:.3f}'.format(k, v))\n",
    "                    checkpoint['metrics_val'][k].append(v)\n",
    "                for k, v in sorted(metrics_train.items()):\n",
    "                    print('  [train] {}: {:.3f}'.format(k, v))\n",
    "                    checkpoint['metrics_train'][k].append(v)\n",
    "\n",
    "                min_ade = min(checkpoint['metrics_val']['ade'])\n",
    "                min_ade_nl = min(checkpoint['metrics_val']['ade_nl'])\n",
    "\n",
    "                if metrics_val['ade'] == min_ade:\n",
    "                    print('New low for avg_disp_error')\n",
    "                    checkpoint['best_t'] = t\n",
    "                    checkpoint['g_best_state'] = generator_S.state_dict()\n",
    "                    checkpoint['d_best_state'] = discriminator_S.state_dict()\n",
    "\n",
    "                if metrics_val['ade_nl'] == min_ade_nl:\n",
    "                    print('New low for avg_disp_error_nl')\n",
    "                    checkpoint['best_t_nl'] = t\n",
    "                    checkpoint['g_best_nl_state'] = generator_S.state_dict()\n",
    "                    checkpoint['d_best_nl_state'] = discriminator_S.state_dict()\n",
    "\n",
    "\n",
    "                checkpoint['g_state'] = generator_S.state_dict()\n",
    "                checkpoint['g_optim_state'] = optimizer_g.state_dict()\n",
    "\n",
    "                checkpoint['d_state'] = discriminator_S.state_dict()\n",
    "                checkpoint['d_optim_state'] = optimizer_d.state_dict()\n",
    "                os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "                checkpoint_path = os.path.join(\n",
    "                    args.output_dir, f'saved_models/{args.dataset_name}_{args.pred_len}_model.pt')\n",
    "                print('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "\n",
    "                torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "\n",
    "            t += 1\n",
    "            d_steps_left = args.d_steps\n",
    "            g_steps_left = args.g_steps\n",
    "            if t >= args.num_iterations:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40851f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T18:19:56.409847Z",
     "start_time": "2023-01-27T18:19:45.910116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/46 [00:10<02:26,  3.40s/it, G_l2=29.6, G_adv=0.67, G_distill=29.6, G_feat=14.9, D=1.36]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce2ea75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T14:45:02.655712Z",
     "start_time": "2023-01-24T14:44:59.953446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on train ...\n"
     ]
    }
   ],
   "source": [
    "metrics_val = train.check_accuracy(\n",
    "    args, val_loader, generator_S, discriminator_S, d_loss_fn\n",
    ")\n",
    "print('Checking stats on train ...')\n",
    "metrics_train = train.check_accuracy(\n",
    "    args, train_loader, generator_S, discriminator_S,\n",
    "    d_loss_fn, limit=True\n",
    ")\n",
    "\n",
    "for k, v in sorted(metrics_val.items()):\n",
    "    print('  [val] {}: {:.3f}'.format(k, v))\n",
    "    checkpoint['metrics_val'][k].append(v)\n",
    "for k, v in sorted(metrics_train.items()):\n",
    "    print('  [train] {}: {:.3f}'.format(k, v))\n",
    "    checkpoint['metrics_train'][k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5d33d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T04:13:02.784928Z",
     "start_time": "2023-01-25T04:13:02.555116Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint1 = torch.load(\"saved_models/hotel_8_model.pt\")\n",
    "checkpoint2 = torch.load(\"models/sgan-p-models/hotel_8_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e701d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T04:13:43.583655Z",
     "start_time": "2023-01-25T04:13:43.577839Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in checkpoint2['args'].keys():\n",
    "    if k not in checkpoint1['args'].keys():\n",
    "        checkpoint1['args'][k] = checkpoint2['args'][k]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff31f628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T04:14:08.719957Z",
     "start_time": "2023-01-25T04:14:07.802411Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(checkpoint1, \"temp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60ac6862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T04:14:31.081832Z",
     "start_time": "2023-01-25T04:14:30.233040Z"
    }
   },
   "outputs": [],
   "source": [
    "!mv temp.pt temp/hotel_8_model.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_11_6",
   "language": "python",
   "name": "cuda_11_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

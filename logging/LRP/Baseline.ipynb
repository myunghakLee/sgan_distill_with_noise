{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596fde5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:22.365077Z",
     "start_time": "2023-01-20T11:53:20.750285Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cuda_11_6/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "from attrdict import AttrDict\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from sgan.losses import displacement_error, final_displacement_error\n",
    "from sgan.losses import gan_g_loss, gan_d_loss, l2_loss\n",
    "\n",
    "from sgan.utils import int_tuple, bool_flag, get_total_norm\n",
    "from sgan.utils import relative_to_abs, get_dset_path\n",
    "\n",
    "from sgan.models import TrajectoryGenerator, TrajectoryDiscriminator\n",
    "from sgan.data.loader import data_loader\n",
    "\n",
    "import train\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cf1be",
   "metadata": {},
   "source": [
    "# Modle Load\n",
    "\n",
    "hotel_8_model.pt : hotel이 아닌 다른 데이터로 학습하고 hotel에서 테스트할 모델. 예측 길이는 8\n",
    "\n",
    "Distillation에서는 일반적으로 generator만 학습하므로 우선 generator만 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde95beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:22.377049Z",
     "start_time": "2023-01-20T11:53:22.367737Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    generator = TrajectoryGenerator(\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        encoder_h_dim=args.encoder_h_dim_g,\n",
    "        decoder_h_dim=args.decoder_h_dim_g,\n",
    "        mlp_dim=args.mlp_dim,\n",
    "        num_layers=args.num_layers,\n",
    "        noise_dim=args.noise_dim,\n",
    "        noise_type=args.noise_type,\n",
    "        noise_mix_type=args.noise_mix_type,\n",
    "        pooling_type=args.pooling_type,\n",
    "        pool_every_timestep=args.pool_every_timestep,\n",
    "        dropout=args.dropout,\n",
    "        bottleneck_dim=args.bottleneck_dim,\n",
    "        neighborhood_size=args.neighborhood_size,\n",
    "        grid_size=args.grid_size,\n",
    "        batch_norm=args.batch_norm)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    generator.cuda()\n",
    "    generator.train()\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def get_discriminator(args):\n",
    "    discriminator = TrajectoryDiscriminator(\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        h_dim=args.encoder_h_dim_d,\n",
    "        mlp_dim=args.mlp_dim,\n",
    "        num_layers=args.num_layers,\n",
    "        dropout=args.dropout,\n",
    "        batch_norm=args.batch_norm,\n",
    "        d_type='local')\n",
    "#         activation='leakyrelu')\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19c684c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:22.417882Z",
     "start_time": "2023-01-20T11:53:22.379657Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        \n",
    "def get_dtypes(args):\n",
    "    long_dtype = torch.LongTensor\n",
    "    float_dtype = torch.FloatTensor\n",
    "    if args.use_gpu == 1:\n",
    "        long_dtype = torch.cuda.LongTensor\n",
    "        float_dtype = torch.cuda.FloatTensor\n",
    "    return long_dtype, float_dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f6565a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:30.883549Z",
     "start_time": "2023-01-20T11:53:22.421820Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./models/sgan-p-models/hotel_8_model.pt\")\n",
    "args = AttrDict(checkpoint['args'])\n",
    "args.output_dir = \"./\"\n",
    "long_dtype, float_dtype = get_dtypes(args)\n",
    "\n",
    "generator_T = get_generator(args)\n",
    "generator_T.load_state_dict(checkpoint['g_state'])\n",
    "\n",
    "generator_S = get_generator(args)\n",
    "generator_S.apply(init_weights)\n",
    "generator_S.type(float_dtype).train()\n",
    "\n",
    "discriminator_S = get_discriminator(args)\n",
    "discriminator_S.apply(init_weights)\n",
    "discriminator_S.type(float_dtype).train()\n",
    "\n",
    "g_loss_fn = gan_g_loss\n",
    "d_loss_fn = gan_d_loss\n",
    "\n",
    "optimizer_g = optim.Adam(generator_S.parameters(), lr=args.g_learning_rate)\n",
    "optimizer_d = optim.Adam(\n",
    "    discriminator_S.parameters(), lr=args.d_learning_rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5852e",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b9e685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:47.693194Z",
     "start_time": "2023-01-20T11:53:30.886660Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = get_dset_path('hotel', 'train')\n",
    "_, train_loader = data_loader(args, train_path)\n",
    "\n",
    "val_path = get_dset_path('hotel', 'val')\n",
    "_, val_loader = data_loader(args, val_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccddf02",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "\n",
    "\n",
    "원본 코드의 학습 구조가 조금 이상하게 되어 있음\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "while(t < args.num_iterations):\n",
    "    d_steps_left = args.d_steps\n",
    "    g_steps_left = args.g_steps\n",
    "    for batch in train_loader:\n",
    "        if d_steps_left > 0:\n",
    "            Train discriminator\n",
    "            d_steps_left -=1\n",
    "           \n",
    "        elif g_steps_left > 0:        \n",
    "            Train generator\n",
    "            g_steps_left -=1\n",
    "        \n",
    "        if d_steps_left > 0 or g_steps_left > 0:\n",
    "            continue\n",
    "        \n",
    "        if t % args.checkpoint_every == 0:\n",
    "            evaluate with val_loader\n",
    "            save model\n",
    "\n",
    "        t += 1\n",
    "        d_steps_left = args.d_steps\n",
    "        g_steps_left = args.g_steps            \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa385aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:47.709481Z",
     "start_time": "2023-01-20T11:53:47.696611Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def discriminator_step(args, batch, generator, discriminator, d_loss_fn, optimizer_d):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "\n",
    "    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "    pred_traj_fake_rel = generator_out\n",
    "    pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "    traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "    traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "    \n",
    "    # Compute loss with optional gradient penalty\n",
    "    data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "    losses['D_data_loss'] = data_loss.item()\n",
    "    loss += data_loss\n",
    "    losses['D_total_loss'] = loss.item()\n",
    "    \n",
    "    \n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_d > 0:\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(),\n",
    "                                 args.clipping_threshold_d)\n",
    "        \n",
    "    optimizer_d.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbe23fd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:47.742074Z",
     "start_time": "2023-01-20T11:53:47.712096Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'args': args.__dict__,\n",
    "    'G_losses': defaultdict(list),\n",
    "    'D_losses': defaultdict(list),\n",
    "    'losses_ts': [],\n",
    "    'metrics_val': defaultdict(list),\n",
    "    'metrics_train': defaultdict(list),\n",
    "    'sample_ts': [],\n",
    "    'restore_ts': [],\n",
    "    'norm_g': [],\n",
    "    'norm_d': [],\n",
    "    'counters': {\n",
    "        't': None,\n",
    "        'epoch': None,\n",
    "    },\n",
    "    'g_state': None,\n",
    "    'g_optim_state': None,\n",
    "    'd_state': None,\n",
    "    'd_optim_state': None,\n",
    "    'g_best_state': None,\n",
    "    'd_best_state': None,\n",
    "    'best_t': None,\n",
    "    'g_best_nl_state': None,\n",
    "    'd_best_state_nl': None,\n",
    "    'best_t_nl': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63c92b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:47.769709Z",
     "start_time": "2023-01-20T11:53:47.744899Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generator_step(args, batch, generator_S, generator_T, discriminator, g_loss_fn, optimizer_g, mode='lrp'):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    \n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_l2_loss_rel = []\n",
    "    g_distill_loss = []\n",
    "    \n",
    "    \n",
    "    loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "    for _ in range(args.best_k):\n",
    "        generator_out_S, feat_S = generator_S(obs_traj, obs_traj_rel, seq_start_end, is_feat=True)\n",
    "        \n",
    "        if mode == 'lrp':\n",
    "            obs_traj_ref, obs_traj_rel_ref = get_lrp(generator_T, obs_traj, obs_traj_rel, pred_traj_gt_rel, seq_start_end)\n",
    "        elif mode == 'random_noise':\n",
    "#             obs_traj_ref += random_noise\n",
    "#             obs_traj_rel_ref += random_noise2\n",
    "            assert False, \"random noise is not ready yet!!!\"\n",
    "            pass\n",
    "            \n",
    "        generator_out_T, feat_T = generator_T(obs_traj_ref, obs_traj_rel_ref, seq_start_end, is_feat=True)\n",
    "#         generator_out_S2, feat_S2 = generator_S(obs_traj_ref, obs_traj_rel_ref, seq_start_end, is_feat=True)\n",
    "\n",
    "        pred_traj_fake_rel_S = generator_out_S\n",
    "        pred_traj_fake_rel_T = generator_out_T\n",
    "\n",
    "        pred_traj_fake_S = relative_to_abs(pred_traj_fake_rel_S, obs_traj[-1])\n",
    "        pred_traj_fake_T = relative_to_abs(pred_traj_fake_rel_T, obs_traj[-1])\n",
    "\n",
    "        if args.l2_loss_weight > 0:\n",
    "            g_l2_loss_rel.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel_S,\n",
    "                pred_traj_gt_rel,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "            \n",
    "            g_distill_loss.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel_S,\n",
    "                pred_traj_fake_rel_T,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "            \n",
    "            \n",
    "    g_l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_distill_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    if args.l2_loss_weight > 0:\n",
    "        g_l2_loss_rel = torch.stack(g_l2_loss_rel, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_l2_loss_rel = g_l2_loss_rel[start:end]\n",
    "            _g_l2_loss_rel = torch.sum(_g_l2_loss_rel, dim=0)\n",
    "            _g_l2_loss_rel = torch.min(_g_l2_loss_rel) / torch.sum(loss_mask[start:end])\n",
    "            g_l2_loss_sum_rel += _g_l2_loss_rel\n",
    "            \n",
    "        losses['G_l2_loss_rel'] = g_l2_loss_sum_rel.item()\n",
    "        loss += g_l2_loss_sum_rel\n",
    "\n",
    "        \n",
    "        g_distill_loss = torch.stack(g_distill_loss, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_distill_loss = g_l2_loss_rel[start:end]\n",
    "            _g_distill_loss = torch.sum(_g_distill_loss, dim=0)\n",
    "            _g_distill_loss = torch.min(_g_distill_loss) / torch.sum(loss_mask[start:end])\n",
    "            g_distill_loss_sum_rel += _g_distill_loss\n",
    "            \n",
    "        losses['g_distill_loss'] = g_distill_loss_sum_rel.item()\n",
    "        loss += g_distill_loss_sum_rel\n",
    "        \n",
    "        loss_feat = 0\n",
    "        for i in range(len(feat_S)):\n",
    "            if isinstance(feat_S[i], tuple):\n",
    "                for j in range(len(feat_S[i])):\n",
    "                    loss_feat += torch.mean((feat_S[i][j] - feat_T[i][j]) ** 2)\n",
    "            else:\n",
    "                loss_feat += torch.mean((feat_S[i] - feat_T[i]) ** 2)\n",
    "                \n",
    "        losses['loss_feat'] = loss_feat.item()\n",
    "        loss += loss_feat\n",
    "        \n",
    "        \n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake_S], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel_S], dim=0)\n",
    "    \n",
    "    if discriminator != None:\n",
    "        scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "        discriminator_loss = g_loss_fn(scores_fake)\n",
    "        loss += discriminator_loss\n",
    "        losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "        losses['G_total_loss'] = loss.item()\n",
    "    else:\n",
    "        discriminator_loss = 0\n",
    "    \n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_g > 0:\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            generator_S.parameters(), args.clipping_threshold_g\n",
    "        )\n",
    "    optimizer_g.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "346017af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T11:53:47.803470Z",
     "start_time": "2023-01-20T11:53:47.772339Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_lrp(generator_T, obs_traj, obs_traj_rel, pred_traj_gt_rel, seq_start_end, alpha = 390, negative = 1):\n",
    "    generator_T.train()\n",
    "    \n",
    "    obs_traj.requires_grad = True\n",
    "    obs_traj_rel.requires_grad = True\n",
    "    \n",
    "    pred = generator_T(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "    loss = torch.mean((pred - pred_traj_gt_rel) ** 2)\n",
    "    loss.backward()\n",
    "\n",
    "    #  ===================================================================\n",
    "    obs_traj_lrp = obs_traj - (obs_traj.grad * torch.abs(obs_traj) * alpha * negative)\n",
    "    obs_traj_rel_lrp = obs_traj_rel - (obs_traj_rel.grad * torch.abs(obs_traj_rel) * alpha * negative)\n",
    "\n",
    "    return obs_traj_lrp, obs_traj_rel_lrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf1b7b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-20T11:53:20.629Z"
    },
    "code_folding": [
     38,
     44
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=17, G_adv=0.68, G_distill=17, G_feat=6.83, D=1.02]      \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=10.1, G_adv=0.687, G_distill=10.1, G_feat=3.4, D=1.32]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=9.5, G_adv=0.693, G_distill=9.5, G_feat=1.62, D=1.01]   \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.83s/it, G_l2=5.41, G_adv=0.693, G_distill=5.41, G_feat=1.05, D=1.4]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=6.87, G_adv=0.684, G_distill=6.87, G_feat=0.765, D=0.934]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=3.49, G_adv=0.666, G_distill=3.49, G_feat=0.579, D=1.07] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=2.09, G_adv=0.691, G_distill=2.09, G_feat=0.483, D=1.32]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=1.25, G_adv=0.692, G_distill=1.25, G_feat=0.398, D=1.17]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=1.64, G_adv=0.692, G_distill=1.64, G_feat=0.298, D=1.34]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=1.48, G_adv=0.689, G_distill=1.48, G_feat=0.353, D=1.33]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=1.16, G_adv=0.692, G_distill=1.16, G_feat=0.339, D=1.29]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=1.27, G_adv=0.688, G_distill=1.27, G_feat=0.273, D=1.33]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.85s/it, G_l2=1.07, G_adv=0.691, G_distill=1.07, G_feat=0.279, D=1.2]   \n",
      "  7%|▋         | 3/46 [00:12<01:32,  2.14s/it, G_l2=1.72, G_adv=0.691, G_distill=1.72, G_feat=0.269, D=1.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 4/46 [00:15<03:12,  4.59s/it, G_l2=1.72, G_adv=0.691, G_distill=1.72, G_feat=0.269, D=1.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 1.514\n",
      "  [val] ade_l: 3.183\n",
      "  [val] ade_nl: 2.886\n",
      "  [val] d_loss: 1.290\n",
      "  [val] fde: 2.737\n",
      "  [val] fde_l: 5.755\n",
      "  [val] fde_nl: 5.219\n",
      "  [val] g_l2_loss_abs: 1.049\n",
      "  [val] g_l2_loss_rel: 1.049\n",
      "  [train] ade: 1.452\n",
      "  [train] ade_l: 3.009\n",
      "  [train] ade_nl: 2.806\n",
      "  [train] d_loss: 1.303\n",
      "  [train] fde: 2.622\n",
      "  [train] fde_l: 5.434\n",
      "  [train] fde_nl: 5.067\n",
      "  [train] g_l2_loss_abs: 0.964\n",
      "  [train] g_l2_loss_rel: 0.964\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=1.01, G_adv=0.689, G_distill=1.01, G_feat=0.293, D=1.19]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.949, G_adv=0.675, G_distill=0.949, G_feat=0.28, D=1.14]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.867, G_adv=0.693, G_distill=0.867, G_feat=0.242, D=1.42]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.841, G_adv=0.693, G_distill=0.841, G_feat=0.284, D=1.4]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.795, G_adv=0.693, G_distill=0.795, G_feat=0.268, D=1.3]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=1.05, G_adv=0.688, G_distill=1.05, G_feat=0.226, D=1.37]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.776, G_adv=0.692, G_distill=0.776, G_feat=0.252, D=1.37]\n",
      "100%|██████████| 46/46 [02:14<00:00,  2.92s/it, G_l2=0.707, G_adv=0.693, G_distill=0.707, G_feat=0.24, D=1.14] \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.759, G_adv=0.689, G_distill=0.759, G_feat=0.27, D=1.38] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.982, G_adv=0.69, G_distill=0.982, G_feat=0.29, D=1.18]  \n",
      "100%|██████████| 46/46 [02:15<00:00,  2.95s/it, G_l2=0.99, G_adv=0.683, G_distill=0.99, G_feat=0.234, D=1.07]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.713, G_adv=0.692, G_distill=0.713, G_feat=0.25, D=1.42] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.606, G_adv=0.689, G_distill=0.606, G_feat=0.163, D=1.33]\n",
      " 11%|█         | 5/46 [00:18<01:36,  2.36s/it, G_l2=0.999, G_adv=0.693, G_distill=0.999, G_feat=0.19, D=1.31] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 7/46 [00:21<01:57,  3.01s/it, G_l2=0.999, G_adv=0.693, G_distill=0.999, G_feat=0.19, D=1.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 1.196\n",
      "  [val] ade_l: 2.516\n",
      "  [val] ade_nl: 2.281\n",
      "  [val] d_loss: 1.340\n",
      "  [val] fde: 2.263\n",
      "  [val] fde_l: 4.758\n",
      "  [val] fde_nl: 4.315\n",
      "  [val] g_l2_loss_abs: 0.698\n",
      "  [val] g_l2_loss_rel: 0.698\n",
      "  [train] ade: 1.232\n",
      "  [train] ade_l: 2.542\n",
      "  [train] ade_nl: 2.391\n",
      "  [train] d_loss: 1.325\n",
      "  [train] fde: 2.305\n",
      "  [train] fde_l: 4.756\n",
      "  [train] fde_nl: 4.473\n",
      "  [train] g_l2_loss_abs: 0.738\n",
      "  [train] g_l2_loss_rel: 0.738\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:14<00:00,  2.93s/it, G_l2=0.881, G_adv=0.682, G_distill=0.881, G_feat=0.179, D=1.31]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.874, G_adv=0.693, G_distill=0.874, G_feat=0.209, D=1.3] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.625, G_adv=0.693, G_distill=0.625, G_feat=0.252, D=1.3] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.734, G_adv=0.67, G_distill=0.734, G_feat=0.155, D=1.32] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.542, G_adv=0.693, G_distill=0.542, G_feat=0.181, D=1.32]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.595, G_adv=0.691, G_distill=0.595, G_feat=0.151, D=1.4] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.813, G_adv=0.692, G_distill=0.813, G_feat=0.179, D=1.24]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.579, G_adv=0.692, G_distill=0.579, G_feat=0.148, D=1.35]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.674, G_adv=0.691, G_distill=0.674, G_feat=0.245, D=1.3] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=1.06, G_adv=0.69, G_distill=1.06, G_feat=0.194, D=1.4]    \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.611, G_adv=0.688, G_distill=0.611, G_feat=0.159, D=1.4] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.698, G_adv=0.69, G_distill=0.698, G_feat=0.148, D=1.22] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.631, G_adv=0.692, G_distill=0.631, G_feat=0.177, D=1.33]\n",
      " 15%|█▌        | 7/46 [00:23<01:31,  2.33s/it, G_l2=0.966, G_adv=0.691, G_distill=0.966, G_feat=0.167, D=1.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9/46 [00:26<01:47,  2.90s/it, G_l2=0.966, G_adv=0.691, G_distill=0.966, G_feat=0.167, D=1.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 1.008\n",
      "  [val] ade_l: 2.119\n",
      "  [val] ade_nl: 1.921\n",
      "  [val] d_loss: 1.334\n",
      "  [val] fde: 1.937\n",
      "  [val] fde_l: 4.073\n",
      "  [val] fde_nl: 3.694\n",
      "  [val] g_l2_loss_abs: 0.503\n",
      "  [val] g_l2_loss_rel: 0.503\n",
      "  [train] ade: 1.002\n",
      "  [train] ade_l: 2.070\n",
      "  [train] ade_nl: 1.940\n",
      "  [train] d_loss: 1.315\n",
      "  [train] fde: 1.928\n",
      "  [train] fde_l: 3.985\n",
      "  [train] fde_nl: 3.736\n",
      "  [train] g_l2_loss_abs: 0.498\n",
      "  [train] g_l2_loss_rel: 0.498\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:14<00:00,  2.93s/it, G_l2=0.54, G_adv=0.692, G_distill=0.54, G_feat=0.183, D=1.24]  \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.637, G_adv=0.693, G_distill=0.637, G_feat=0.169, D=1.38]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.635, G_adv=0.69, G_distill=0.635, G_feat=0.159, D=1.3]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.765, G_adv=0.692, G_distill=0.765, G_feat=0.227, D=1.35]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.664, G_adv=0.692, G_distill=0.664, G_feat=0.153, D=1.39]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.776, G_adv=0.692, G_distill=0.776, G_feat=0.168, D=1.25]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.53, G_adv=0.693, G_distill=0.53, G_feat=0.164, D=1.38]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.983, G_adv=0.687, G_distill=0.983, G_feat=0.169, D=1.35]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.558, G_adv=0.693, G_distill=0.558, G_feat=0.198, D=1.41]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.768, G_adv=0.693, G_distill=0.768, G_feat=0.188, D=1.39]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.85s/it, G_l2=0.669, G_adv=0.69, G_distill=0.669, G_feat=0.171, D=1.21] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.714, G_adv=0.686, G_distill=0.714, G_feat=0.29, D=1.39] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.774, G_adv=0.691, G_distill=0.774, G_feat=0.165, D=1.38]\n",
      " 20%|█▉        | 9/46 [00:30<01:31,  2.47s/it, G_l2=0.932, G_adv=0.692, G_distill=0.932, G_feat=0.13, D=1.39] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 11/46 [00:33<01:45,  3.03s/it, G_l2=0.932, G_adv=0.692, G_distill=0.932, G_feat=0.13, D=1.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.927\n",
      "  [val] ade_l: 1.949\n",
      "  [val] ade_nl: 1.767\n",
      "  [val] d_loss: 1.327\n",
      "  [val] fde: 1.812\n",
      "  [val] fde_l: 3.811\n",
      "  [val] fde_nl: 3.456\n",
      "  [val] g_l2_loss_abs: 0.446\n",
      "  [val] g_l2_loss_rel: 0.446\n",
      "  [train] ade: 0.902\n",
      "  [train] ade_l: 1.851\n",
      "  [train] ade_nl: 1.760\n",
      "  [train] d_loss: 1.288\n",
      "  [train] fde: 1.754\n",
      "  [train] fde_l: 3.599\n",
      "  [train] fde_nl: 3.422\n",
      "  [train] g_l2_loss_abs: 0.423\n",
      "  [train] g_l2_loss_rel: 0.423\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:15<00:00,  2.94s/it, G_l2=0.876, G_adv=0.689, G_distill=0.876, G_feat=0.194, D=1.4] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.598, G_adv=0.692, G_distill=0.598, G_feat=0.151, D=1.29]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.627, G_adv=0.688, G_distill=0.627, G_feat=0.161, D=1.4] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.537, G_adv=0.69, G_distill=0.537, G_feat=0.172, D=1.17] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.554, G_adv=0.693, G_distill=0.554, G_feat=0.158, D=1.33]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.825, G_adv=0.69, G_distill=0.825, G_feat=0.18, D=1.4]   \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.74, G_adv=0.676, G_distill=0.74, G_feat=0.144, D=1.35]  \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.863, G_adv=0.684, G_distill=0.863, G_feat=0.202, D=1.2] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.859, G_adv=0.688, G_distill=0.859, G_feat=0.155, D=1.33]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.582, G_adv=0.69, G_distill=0.582, G_feat=0.127, D=1.25] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.528, G_adv=0.693, G_distill=0.528, G_feat=0.15, D=1.38] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.772, G_adv=0.69, G_distill=0.772, G_feat=0.186, D=1.15] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.618, G_adv=0.679, G_distill=0.618, G_feat=0.16, D=1.12] \n",
      " 24%|██▍       | 11/46 [00:35<01:23,  2.40s/it, G_l2=0.685, G_adv=0.693, G_distill=0.685, G_feat=0.144, D=1.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 13/46 [00:38<01:36,  2.94s/it, G_l2=0.685, G_adv=0.693, G_distill=0.685, G_feat=0.144, D=1.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.871\n",
      "  [val] ade_l: 1.832\n",
      "  [val] ade_nl: 1.661\n",
      "  [val] d_loss: 1.318\n",
      "  [val] fde: 1.711\n",
      "  [val] fde_l: 3.598\n",
      "  [val] fde_nl: 3.263\n",
      "  [val] g_l2_loss_abs: 0.408\n",
      "  [val] g_l2_loss_rel: 0.408\n",
      "  [train] ade: 0.845\n",
      "  [train] ade_l: 1.775\n",
      "  [train] ade_nl: 1.612\n",
      "  [train] d_loss: 1.275\n",
      "  [train] fde: 1.653\n",
      "  [train] fde_l: 3.473\n",
      "  [train] fde_nl: 3.154\n",
      "  [train] g_l2_loss_abs: 0.378\n",
      "  [train] g_l2_loss_rel: 0.378\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:14<00:00,  2.91s/it, G_l2=0.549, G_adv=0.689, G_distill=0.549, G_feat=0.169, D=1.38]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.522, G_adv=0.691, G_distill=0.522, G_feat=0.142, D=1.12]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.75, G_adv=0.654, G_distill=0.75, G_feat=0.179, D=1.12]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.545, G_adv=0.685, G_distill=0.545, G_feat=0.197, D=1.14] \n",
      "100%|██████████| 46/46 [02:08<00:00,  2.80s/it, G_l2=0.812, G_adv=0.689, G_distill=0.812, G_feat=0.155, D=1.36] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.65, G_adv=0.688, G_distill=0.65, G_feat=0.145, D=1.03]   \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.501, G_adv=0.691, G_distill=0.501, G_feat=0.232, D=0.931]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.85s/it, G_l2=0.465, G_adv=0.687, G_distill=0.465, G_feat=0.187, D=1.38] \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.481, G_adv=0.673, G_distill=0.481, G_feat=0.168, D=1.08] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.842, G_adv=0.683, G_distill=0.842, G_feat=0.212, D=1.01] \n",
      "100%|██████████| 46/46 [02:15<00:00,  2.95s/it, G_l2=0.66, G_adv=0.681, G_distill=0.66, G_feat=0.206, D=1.28]   \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.746, G_adv=0.673, G_distill=0.746, G_feat=0.15, D=1.07]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.551, G_adv=0.69, G_distill=0.551, G_feat=0.126, D=1.29]  \n",
      " 28%|██▊       | 13/46 [00:42<01:19,  2.40s/it, G_l2=0.852, G_adv=0.687, G_distill=0.852, G_feat=0.124, D=1.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 15/46 [00:44<01:32,  2.98s/it, G_l2=0.852, G_adv=0.687, G_distill=0.852, G_feat=0.124, D=1.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.888\n",
      "  [val] ade_l: 1.868\n",
      "  [val] ade_nl: 1.694\n",
      "  [val] d_loss: 1.206\n",
      "  [val] fde: 1.754\n",
      "  [val] fde_l: 3.689\n",
      "  [val] fde_nl: 3.345\n",
      "  [val] g_l2_loss_abs: 0.423\n",
      "  [val] g_l2_loss_rel: 0.423\n",
      "  [train] ade: 0.839\n",
      "  [train] ade_l: 1.711\n",
      "  [train] ade_nl: 1.644\n",
      "  [train] d_loss: 1.115\n",
      "  [train] fde: 1.657\n",
      "  [train] fde_l: 3.382\n",
      "  [train] fde_nl: 3.250\n",
      "  [train] g_l2_loss_abs: 0.383\n",
      "  [train] g_l2_loss_rel: 0.383\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:14<00:00,  2.92s/it, G_l2=0.657, G_adv=0.654, G_distill=0.657, G_feat=0.146, D=1.1]  \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.566, G_adv=0.692, G_distill=0.566, G_feat=0.173, D=1.12] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.771, G_adv=0.692, G_distill=0.771, G_feat=0.206, D=0.946]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.83s/it, G_l2=0.872, G_adv=0.686, G_distill=0.872, G_feat=0.244, D=1.25] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.621, G_adv=0.673, G_distill=0.621, G_feat=0.174, D=1.51] \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.83s/it, G_l2=0.677, G_adv=0.681, G_distill=0.677, G_feat=0.173, D=0.945]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.696, G_adv=0.692, G_distill=0.696, G_feat=0.212, D=1.01] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.639, G_adv=0.659, G_distill=0.639, G_feat=0.151, D=1.23] \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.565, G_adv=0.685, G_distill=0.565, G_feat=0.201, D=1.22] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.848, G_adv=0.687, G_distill=0.848, G_feat=0.194, D=0.797]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.562, G_adv=0.684, G_distill=0.562, G_feat=0.208, D=1.48] \n",
      "100%|██████████| 46/46 [02:16<00:00,  2.96s/it, G_l2=0.659, G_adv=0.662, G_distill=0.659, G_feat=0.161, D=0.787]\n",
      "100%|██████████| 46/46 [02:17<00:00,  2.98s/it, G_l2=0.752, G_adv=0.685, G_distill=0.752, G_feat=0.126, D=1.39] \n",
      " 33%|███▎      | 15/46 [00:48<01:17,  2.51s/it, G_l2=0.767, G_adv=0.664, G_distill=0.767, G_feat=0.134, D=1.23] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 17/46 [00:51<01:29,  3.08s/it, G_l2=0.767, G_adv=0.664, G_distill=0.767, G_feat=0.134, D=1.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.863\n",
      "  [val] ade_l: 1.816\n",
      "  [val] ade_nl: 1.646\n",
      "  [val] d_loss: 0.956\n",
      "  [val] fde: 1.712\n",
      "  [val] fde_l: 3.599\n",
      "  [val] fde_nl: 3.264\n",
      "  [val] g_l2_loss_abs: 0.409\n",
      "  [val] g_l2_loss_rel: 0.409\n",
      "  [train] ade: 0.839\n",
      "  [train] ade_l: 1.795\n",
      "  [train] ade_nl: 1.574\n",
      "  [train] d_loss: 1.174\n",
      "  [train] fde: 1.653\n",
      "  [train] fde_l: 3.539\n",
      "  [train] fde_nl: 3.102\n",
      "  [train] g_l2_loss_abs: 0.370\n",
      "  [train] g_l2_loss_rel: 0.370\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:15<00:00,  2.95s/it, G_l2=0.622, G_adv=0.656, G_distill=0.622, G_feat=0.177, D=0.809]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.484, G_adv=0.687, G_distill=0.484, G_feat=0.187, D=1.48] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.762, G_adv=0.692, G_distill=0.762, G_feat=0.165, D=1.09] \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.652, G_adv=0.653, G_distill=0.652, G_feat=0.175, D=0.711]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.852, G_adv=0.637, G_distill=0.852, G_feat=0.16, D=0.711] \n",
      "100%|██████████| 46/46 [02:14<00:00,  2.91s/it, G_l2=0.72, G_adv=0.652, G_distill=0.72, G_feat=0.159, D=1.07]   \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.501, G_adv=0.674, G_distill=0.501, G_feat=0.137, D=0.865]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.768, G_adv=0.686, G_distill=0.768, G_feat=0.201, D=1.35] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.518, G_adv=0.675, G_distill=0.518, G_feat=0.229, D=1.49] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.585, G_adv=0.677, G_distill=0.585, G_feat=0.175, D=1.2]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.699, G_adv=0.686, G_distill=0.699, G_feat=0.124, D=1.08] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.649, G_adv=0.684, G_distill=0.649, G_feat=0.156, D=0.943]\n",
      "100%|██████████| 46/46 [02:10<00:00,  2.84s/it, G_l2=0.591, G_adv=0.668, G_distill=0.591, G_feat=0.146, D=0.64] \n",
      " 37%|███▋      | 17/46 [00:56<01:21,  2.83s/it, G_l2=0.599, G_adv=0.68, G_distill=0.599, G_feat=0.116, D=0.652] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 19/46 [00:58<01:26,  3.19s/it, G_l2=0.599, G_adv=0.68, G_distill=0.599, G_feat=0.116, D=0.652]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.846\n",
      "  [val] ade_l: 1.779\n",
      "  [val] ade_nl: 1.613\n",
      "  [val] d_loss: 1.093\n",
      "  [val] fde: 1.683\n",
      "  [val] fde_l: 3.539\n",
      "  [val] fde_nl: 3.209\n",
      "  [val] g_l2_loss_abs: 0.409\n",
      "  [val] g_l2_loss_rel: 0.409\n",
      "  [train] ade: 0.802\n",
      "  [train] ade_l: 1.663\n",
      "  [train] ade_nl: 1.549\n",
      "  [train] d_loss: 1.014\n",
      "  [train] fde: 1.596\n",
      "  [train] fde_l: 3.310\n",
      "  [train] fde_nl: 3.083\n",
      "  [train] g_l2_loss_abs: 0.353\n",
      "  [train] g_l2_loss_rel: 0.353\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:17<00:00,  2.99s/it, G_l2=0.667, G_adv=0.67, G_distill=0.667, G_feat=0.191, D=0.525] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.668, G_adv=0.689, G_distill=0.668, G_feat=0.134, D=0.816]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.89s/it, G_l2=0.591, G_adv=0.692, G_distill=0.591, G_feat=0.273, D=1.42] \n",
      "100%|██████████| 46/46 [02:09<00:00,  2.82s/it, G_l2=0.493, G_adv=0.69, G_distill=0.493, G_feat=0.152, D=1.22]  \n",
      "100%|██████████| 46/46 [02:15<00:00,  2.93s/it, G_l2=0.793, G_adv=0.661, G_distill=0.793, G_feat=0.146, D=0.997]\n",
      "100%|██████████| 46/46 [02:16<00:00,  2.96s/it, G_l2=0.637, G_adv=0.67, G_distill=0.637, G_feat=0.124, D=1.52]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.513, G_adv=0.684, G_distill=0.513, G_feat=0.126, D=1.65] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.533, G_adv=0.641, G_distill=0.533, G_feat=0.17, D=0.94]  \n",
      "100%|██████████| 46/46 [02:14<00:00,  2.92s/it, G_l2=0.747, G_adv=0.689, G_distill=0.747, G_feat=0.187, D=1.5]  \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.443, G_adv=0.688, G_distill=0.443, G_feat=0.212, D=1.46] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.577, G_adv=0.675, G_distill=0.577, G_feat=0.14, D=1.49]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.601, G_adv=0.663, G_distill=0.601, G_feat=0.217, D=1.54] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.667, G_adv=0.689, G_distill=0.667, G_feat=0.164, D=1.01] \n",
      " 41%|████▏     | 19/46 [01:00<01:06,  2.46s/it, G_l2=0.757, G_adv=0.674, G_distill=0.757, G_feat=0.15, D=0.935] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 21/46 [01:02<01:15,  3.03s/it, G_l2=0.757, G_adv=0.674, G_distill=0.757, G_feat=0.15, D=0.935]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.793\n",
      "  [val] ade_l: 1.667\n",
      "  [val] ade_nl: 1.512\n",
      "  [val] d_loss: 0.989\n",
      "  [val] fde: 1.585\n",
      "  [val] fde_l: 3.333\n",
      "  [val] fde_nl: 3.022\n",
      "  [val] g_l2_loss_abs: 0.362\n",
      "  [val] g_l2_loss_rel: 0.362\n",
      "  [train] ade: 0.776\n",
      "  [train] ade_l: 1.640\n",
      "  [train] ade_nl: 1.473\n",
      "  [train] d_loss: 0.885\n",
      "  [train] fde: 1.556\n",
      "  [train] fde_l: 3.287\n",
      "  [train] fde_nl: 2.953\n",
      "  [train] g_l2_loss_abs: 0.340\n",
      "  [train] g_l2_loss_rel: 0.340\n",
      "New low for avg_disp_error\n",
      "New low for avg_disp_error_nl\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:15<00:00,  2.95s/it, G_l2=0.611, G_adv=0.687, G_distill=0.611, G_feat=0.156, D=1.3]  \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.609, G_adv=0.671, G_distill=0.609, G_feat=0.152, D=0.65] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.616, G_adv=0.671, G_distill=0.616, G_feat=0.174, D=1.27] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.643, G_adv=0.691, G_distill=0.643, G_feat=0.212, D=1.1]  \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.606, G_adv=0.688, G_distill=0.606, G_feat=0.121, D=1.4]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.587, G_adv=0.691, G_distill=0.587, G_feat=0.119, D=1.29] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.606, G_adv=0.654, G_distill=0.606, G_feat=0.195, D=0.453]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.846, G_adv=0.691, G_distill=0.846, G_feat=0.126, D=0.781]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.59, G_adv=0.684, G_distill=0.59, G_feat=0.155, D=1.43]   \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.659, G_adv=0.683, G_distill=0.659, G_feat=0.14, D=0.97]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.656, G_adv=0.687, G_distill=0.656, G_feat=0.142, D=0.804]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.86s/it, G_l2=0.538, G_adv=0.684, G_distill=0.538, G_feat=0.13, D=0.652] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.474, G_adv=0.676, G_distill=0.474, G_feat=0.171, D=0.619] \n",
      " 46%|████▌     | 21/46 [01:03<00:58,  2.33s/it, G_l2=0.648, G_adv=0.688, G_distill=0.648, G_feat=0.112, D=0.835]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 23/46 [01:06<01:06,  2.89s/it, G_l2=0.648, G_adv=0.688, G_distill=0.648, G_feat=0.112, D=0.835]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.866\n",
      "  [val] ade_l: 1.821\n",
      "  [val] ade_nl: 1.651\n",
      "  [val] d_loss: 0.831\n",
      "  [val] fde: 1.718\n",
      "  [val] fde_l: 3.613\n",
      "  [val] fde_nl: 3.276\n",
      "  [val] g_l2_loss_abs: 0.413\n",
      "  [val] g_l2_loss_rel: 0.413\n",
      "  [train] ade: 0.825\n",
      "  [train] ade_l: 1.674\n",
      "  [train] ade_nl: 1.626\n",
      "  [train] d_loss: 1.117\n",
      "  [train] fde: 1.649\n",
      "  [train] fde_l: 3.347\n",
      "  [train] fde_nl: 3.250\n",
      "  [train] g_l2_loss_abs: 0.369\n",
      "  [train] g_l2_loss_rel: 0.369\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:14<00:00,  2.91s/it, G_l2=0.719, G_adv=0.672, G_distill=0.719, G_feat=0.119, D=1.27] \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.694, G_adv=0.692, G_distill=0.694, G_feat=0.166, D=1.12] \n",
      "100%|██████████| 46/46 [02:03<00:00,  2.69s/it, G_l2=0.919, G_adv=0.687, G_distill=0.919, G_feat=0.156, D=0.463]\n",
      "100%|██████████| 46/46 [02:11<00:00,  2.87s/it, G_l2=0.497, G_adv=0.688, G_distill=0.497, G_feat=0.128, D=0.928]\n",
      "100%|██████████| 46/46 [02:14<00:00,  2.92s/it, G_l2=0.525, G_adv=0.692, G_distill=0.525, G_feat=0.256, D=1.07]  \n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.606, G_adv=0.692, G_distill=0.606, G_feat=0.139, D=1.43] \n",
      "100%|██████████| 46/46 [02:11<00:00,  2.85s/it, G_l2=0.64, G_adv=0.682, G_distill=0.64, G_feat=0.175, D=0.977]  \n",
      "100%|██████████| 46/46 [02:10<00:00,  2.83s/it, G_l2=0.594, G_adv=0.688, G_distill=0.594, G_feat=0.121, D=0.606]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.87s/it, G_l2=0.513, G_adv=0.692, G_distill=0.513, G_feat=0.121, D=1.5]  \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.90s/it, G_l2=0.612, G_adv=0.679, G_distill=0.612, G_feat=0.154, D=0.758]\n",
      "100%|██████████| 46/46 [02:12<00:00,  2.88s/it, G_l2=0.718, G_adv=0.684, G_distill=0.718, G_feat=0.162, D=0.397]\n",
      "100%|██████████| 46/46 [02:13<00:00,  2.91s/it, G_l2=0.846, G_adv=0.686, G_distill=0.846, G_feat=0.142, D=1.15] \n",
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.595, G_adv=0.689, G_distill=0.595, G_feat=0.152, D=1.5]  \n",
      " 50%|█████     | 23/46 [01:08<00:54,  2.37s/it, G_l2=0.756, G_adv=0.679, G_distill=0.756, G_feat=0.123, D=0.556]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 25/46 [01:11<01:01,  2.93s/it, G_l2=0.756, G_adv=0.679, G_distill=0.756, G_feat=0.123, D=0.556]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.813\n",
      "  [val] ade_l: 1.710\n",
      "  [val] ade_nl: 1.550\n",
      "  [val] d_loss: 0.949\n",
      "  [val] fde: 1.626\n",
      "  [val] fde_l: 3.419\n",
      "  [val] fde_nl: 3.100\n",
      "  [val] g_l2_loss_abs: 0.383\n",
      "  [val] g_l2_loss_rel: 0.383\n",
      "  [train] ade: 0.779\n",
      "  [train] ade_l: 1.586\n",
      "  [train] ade_nl: 1.531\n",
      "  [train] d_loss: 0.850\n",
      "  [train] fde: 1.569\n",
      "  [train] fde_l: 3.195\n",
      "  [train] fde_nl: 3.084\n",
      "  [train] g_l2_loss_abs: 0.346\n",
      "  [train] g_l2_loss_rel: 0.346\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:13<00:00,  2.89s/it, G_l2=0.631, G_adv=0.691, G_distill=0.631, G_feat=0.154, D=0.928]\n",
      "100%|██████████| 46/46 [02:09<00:00,  2.82s/it, G_l2=0.755, G_adv=0.69, G_distill=0.755, G_feat=0.188, D=1.1]   \n",
      "100%|██████████| 46/46 [02:09<00:00,  2.82s/it, G_l2=0.473, G_adv=0.673, G_distill=0.473, G_feat=0.194, D=1.61] \n",
      "100%|██████████| 46/46 [02:27<00:00,  3.21s/it, G_l2=0.896, G_adv=0.677, G_distill=0.896, G_feat=0.231, D=0.767]\n",
      "100%|██████████| 46/46 [04:14<00:00,  5.54s/it, G_l2=0.574, G_adv=0.687, G_distill=0.574, G_feat=0.15, D=1.18]  \n",
      "100%|██████████| 46/46 [04:32<00:00,  5.93s/it, G_l2=0.524, G_adv=0.687, G_distill=0.524, G_feat=0.12, D=0.36]  \n",
      "100%|██████████| 46/46 [04:02<00:00,  5.28s/it, G_l2=0.501, G_adv=0.683, G_distill=0.501, G_feat=0.151, D=1.62] \n",
      "100%|██████████| 46/46 [02:09<00:00,  2.81s/it, G_l2=0.714, G_adv=0.668, G_distill=0.714, G_feat=0.144, D=0.803]\n",
      "100%|██████████| 46/46 [02:09<00:00,  2.81s/it, G_l2=0.62, G_adv=0.687, G_distill=0.62, G_feat=0.185, D=1.07]   \n",
      "100%|██████████| 46/46 [02:09<00:00,  2.82s/it, G_l2=0.425, G_adv=0.691, G_distill=0.425, G_feat=0.201, D=1.28] \n",
      "100%|██████████| 46/46 [02:50<00:00,  3.71s/it, G_l2=0.519, G_adv=0.68, G_distill=0.519, G_feat=0.183, D=0.439] \n",
      "100%|██████████| 46/46 [04:14<00:00,  5.54s/it, G_l2=0.54, G_adv=0.69, G_distill=0.54, G_feat=0.204, D=1.12]     \n",
      "100%|██████████| 46/46 [03:15<00:00,  4.25s/it, G_l2=0.485, G_adv=0.687, G_distill=0.485, G_feat=0.143, D=1.51] \n",
      " 54%|█████▍    | 25/46 [01:19<00:57,  2.74s/it, G_l2=0.9, G_adv=0.677, G_distill=0.9, G_feat=0.12, D=0.739]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 26/46 [01:22<01:43,  5.16s/it, G_l2=0.9, G_adv=0.677, G_distill=0.9, G_feat=0.12, D=0.739]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.826\n",
      "  [val] ade_l: 1.737\n",
      "  [val] ade_nl: 1.575\n",
      "  [val] d_loss: 0.824\n",
      "  [val] fde: 1.652\n",
      "  [val] fde_l: 3.474\n",
      "  [val] fde_nl: 3.151\n",
      "  [val] g_l2_loss_abs: 0.386\n",
      "  [val] g_l2_loss_rel: 0.386\n",
      "  [train] ade: 0.780\n",
      "  [train] ade_l: 1.578\n",
      "  [train] ade_nl: 1.542\n",
      "  [train] d_loss: 0.698\n",
      "  [train] fde: 1.571\n",
      "  [train] fde_l: 3.178\n",
      "  [train] fde_nl: 3.105\n",
      "  [train] g_l2_loss_abs: 0.340\n",
      "  [train] g_l2_loss_rel: 0.340\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:42<00:00,  3.53s/it, G_l2=0.666, G_adv=0.686, G_distill=0.666, G_feat=0.157, D=0.745]\n",
      "100%|██████████| 46/46 [03:59<00:00,  5.20s/it, G_l2=0.557, G_adv=0.691, G_distill=0.557, G_feat=0.158, D=0.853]\n",
      "100%|██████████| 46/46 [03:55<00:00,  5.12s/it, G_l2=0.709, G_adv=0.69, G_distill=0.709, G_feat=0.169, D=0.765] \n",
      "100%|██████████| 46/46 [03:57<00:00,  5.15s/it, G_l2=0.644, G_adv=0.686, G_distill=0.644, G_feat=0.17, D=1.22]  \n",
      "100%|██████████| 46/46 [03:55<00:00,  5.13s/it, G_l2=0.849, G_adv=0.684, G_distill=0.849, G_feat=0.132, D=1.25] \n",
      "100%|██████████| 46/46 [03:51<00:00,  5.03s/it, G_l2=0.682, G_adv=0.689, G_distill=0.682, G_feat=0.128, D=1.42] \n",
      "100%|██████████| 46/46 [03:41<00:00,  4.82s/it, G_l2=0.819, G_adv=0.687, G_distill=0.819, G_feat=0.169, D=1.25] \n",
      "100%|██████████| 46/46 [03:44<00:00,  4.89s/it, G_l2=0.443, G_adv=0.691, G_distill=0.443, G_feat=0.124, D=1.07] \n",
      "100%|██████████| 46/46 [03:42<00:00,  4.84s/it, G_l2=0.69, G_adv=0.692, G_distill=0.69, G_feat=0.151, D=0.843]  \n",
      "100%|██████████| 46/46 [03:43<00:00,  4.87s/it, G_l2=0.488, G_adv=0.685, G_distill=0.488, G_feat=0.121, D=0.791]\n",
      "100%|██████████| 46/46 [03:46<00:00,  4.93s/it, G_l2=0.537, G_adv=0.69, G_distill=0.537, G_feat=0.137, D=1.37]  \n",
      "100%|██████████| 46/46 [03:42<00:00,  4.84s/it, G_l2=0.64, G_adv=0.688, G_distill=0.64, G_feat=0.159, D=0.421]  \n",
      "100%|██████████| 46/46 [03:40<00:00,  4.80s/it, G_l2=0.754, G_adv=0.691, G_distill=0.754, G_feat=0.179, D=1.5]  \n",
      " 59%|█████▊    | 27/46 [02:18<01:17,  4.06s/it, G_l2=0.755, G_adv=0.687, G_distill=0.755, G_feat=0.135, D=0.896] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stats on val ...\n",
      "Checking stats on train ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 28/46 [02:23<02:09,  7.20s/it, G_l2=0.755, G_adv=0.687, G_distill=0.755, G_feat=0.135, D=0.896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.829\n",
      "  [val] ade_l: 1.744\n",
      "  [val] ade_nl: 1.581\n",
      "  [val] d_loss: 0.966\n",
      "  [val] fde: 1.659\n",
      "  [val] fde_l: 3.489\n",
      "  [val] fde_nl: 3.164\n",
      "  [val] g_l2_loss_abs: 0.383\n",
      "  [val] g_l2_loss_rel: 0.383\n",
      "  [train] ade: 0.788\n",
      "  [train] ade_l: 1.594\n",
      "  [train] ade_nl: 1.558\n",
      "  [train] d_loss: 0.910\n",
      "  [train] fde: 1.574\n",
      "  [train] fde_l: 3.185\n",
      "  [train] fde_nl: 3.112\n",
      "  [train] g_l2_loss_abs: 0.342\n",
      "  [train] g_l2_loss_rel: 0.342\n",
      "Saving checkpoint to ./saved_models/S_hotel_8_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [03:50<00:00,  5.01s/it, G_l2=0.502, G_adv=0.684, G_distill=0.502, G_feat=0.12, D=0.664] \n",
      "100%|██████████| 46/46 [03:39<00:00,  4.78s/it, G_l2=0.555, G_adv=0.691, G_distill=0.555, G_feat=0.159, D=0.901]\n",
      "100%|██████████| 46/46 [03:42<00:00,  4.84s/it, G_l2=0.636, G_adv=0.691, G_distill=0.636, G_feat=0.123, D=0.71]  \n",
      "100%|██████████| 46/46 [03:41<00:00,  4.81s/it, G_l2=0.555, G_adv=0.689, G_distill=0.555, G_feat=0.197, D=0.948]\n",
      "100%|██████████| 46/46 [03:42<00:00,  4.84s/it, G_l2=0.884, G_adv=0.678, G_distill=0.884, G_feat=0.115, D=1.36] \n",
      "100%|██████████| 46/46 [03:46<00:00,  4.92s/it, G_l2=0.616, G_adv=0.687, G_distill=0.616, G_feat=0.163, D=1.64] \n",
      "100%|██████████| 46/46 [03:42<00:00,  4.83s/it, G_l2=0.515, G_adv=0.689, G_distill=0.515, G_feat=0.212, D=0.95] \n",
      " 85%|████████▍ | 39/46 [03:07<00:29,  4.14s/it, G_l2=0.855, G_adv=0.684, G_distill=0.855, G_feat=0.164, D=0.287]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "t = 0\n",
    "epoch = 0\n",
    "while t < args.num_iterations:\n",
    "    gc.collect()\n",
    "    d_steps_left = args.d_steps\n",
    "    g_steps_left = args.g_steps\n",
    "    epoch += 1\n",
    "    \n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        \n",
    "        if d_steps_left > 0:\n",
    "            step_type = 'd'\n",
    "            losses_d = discriminator_step(args, batch, generator_S,\n",
    "                                          discriminator_S, d_loss_fn,\n",
    "                                          optimizer_d)\n",
    "            d_steps_left -= 1\n",
    "        elif g_steps_left > 0:\n",
    "            step_type = 'g'\n",
    "            losses_g = generator_step(args, batch, generator_S, generator_T,\n",
    "                                      discriminator_S, g_loss_fn,\n",
    "                                      optimizer_g)\n",
    "            g_steps_left -= 1\n",
    "\n",
    "        # 여기 밑으로는 그냥 evaluation하고 모델 저장하는 부분\n",
    "        if d_steps_left > 0 or g_steps_left > 0:\n",
    "            continue\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            \"G_l2\" : losses_g['G_l2_loss_rel'],\n",
    "            \"G_adv\" : losses_g['G_discriminator_loss'],\n",
    "            \"G_distill\" : losses_g['g_distill_loss'],\n",
    "            \"G_feat\" : losses_g['loss_feat'],\n",
    "            \"D\" : losses_d['D_total_loss']\n",
    "        })\n",
    "        \n",
    "        # Maybe save a checkpoint\n",
    "        if t > 0 and t % args.checkpoint_every == 0:\n",
    "#         if True:\n",
    "            print('Checking stats on val ...')\n",
    "            metrics_val = train.check_accuracy(\n",
    "                args, val_loader, generator_S, discriminator_S, d_loss_fn\n",
    "            )\n",
    "            print('Checking stats on train ...')\n",
    "            metrics_train = train.check_accuracy(\n",
    "                args, train_loader, generator_S, discriminator_S,\n",
    "                d_loss_fn, limit=True\n",
    "            )\n",
    "\n",
    "            for k, v in sorted(metrics_val.items()):\n",
    "                print('  [val] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_val'][k].append(v)\n",
    "            for k, v in sorted(metrics_train.items()):\n",
    "                print('  [train] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_train'][k].append(v)\n",
    "\n",
    "            min_ade = min(checkpoint['metrics_val']['ade'])\n",
    "            min_ade_nl = min(checkpoint['metrics_val']['ade_nl'])\n",
    "\n",
    "            if metrics_val['ade'] == min_ade:\n",
    "                print('New low for avg_disp_error')\n",
    "                checkpoint['best_t'] = t\n",
    "                checkpoint['g_best_state'] = generator_S.state_dict()\n",
    "                checkpoint['d_best_state'] = discriminator_S.state_dict()\n",
    "\n",
    "            if metrics_val['ade_nl'] == min_ade_nl:\n",
    "                print('New low for avg_disp_error_nl')\n",
    "                checkpoint['best_t_nl'] = t\n",
    "                checkpoint['g_best_nl_state'] = generator_S.state_dict()\n",
    "                checkpoint['d_best_nl_state'] = discriminator_S.state_dict()\n",
    "\n",
    "\n",
    "            checkpoint['g_state'] = generator_S.state_dict()\n",
    "            checkpoint['g_optim_state'] = optimizer_g.state_dict()\n",
    "            \n",
    "            checkpoint['d_state'] = discriminator_S.state_dict()\n",
    "            checkpoint['d_optim_state'] = optimizer_d.state_dict()\n",
    "            os.makedirs(\"saved_models\", exist_ok=True)\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, f'saved_models/S_{args.dataset_name}_{args.pred_len}_model.pt')\n",
    "            print('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "\n",
    "        t += 1\n",
    "        d_steps_left = args.d_steps\n",
    "        g_steps_left = args.g_steps\n",
    "        if t >= args.num_iterations:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce2ea75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T09:04:11.572730Z",
     "start_time": "2023-01-25T09:04:11.249442Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mcheck_accuracy(\n\u001b[1;32m      2\u001b[0m     args, val_loader, generator_S, discriminator_S, d_loss_fn\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChecking stats on train ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m metrics_train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mcheck_accuracy(\n\u001b[1;32m      6\u001b[0m     args, train_loader, generator_S, discriminator_S,\n\u001b[1;32m      7\u001b[0m     d_loss_fn, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_val = train.check_accuracy(\n",
    "    args, val_loader, generator_S, discriminator_S, d_loss_fn\n",
    ")\n",
    "print('Checking stats on train ...')\n",
    "metrics_train = train.check_accuracy(\n",
    "    args, train_loader, generator_S, discriminator_S,\n",
    "    d_loss_fn, limit=True\n",
    ")\n",
    "for k, v in sorted(metrics_val.items()):\n",
    "    print('  [val] {}: {:.3f}'.format(k, v))\n",
    "    checkpoint['metrics_val'][k].append(v)\n",
    "for k, v in sorted(metrics_train.items()):\n",
    "    print('  [train] {}: {:.3f}'.format(k, v))\n",
    "    checkpoint['metrics_train'][k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aa53400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T14:45:18.893909Z",
     "start_time": "2023-01-24T14:45:18.886328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [val] ade: 0.787\n",
      "  [val] ade_l: 1.656\n",
      "  [val] ade_nl: 1.501\n",
      "  [val] d_loss: 0.817\n",
      "  [val] fde: 1.606\n",
      "  [val] fde_l: 3.377\n",
      "  [val] fde_nl: 3.062\n",
      "  [val] g_l2_loss_abs: 0.372\n",
      "  [val] g_l2_loss_rel: 0.372\n",
      "  [train] ade: 0.719\n",
      "  [train] ade_l: 1.464\n",
      "  [train] ade_nl: 1.414\n",
      "  [train] d_loss: 0.953\n",
      "  [train] fde: 1.460\n",
      "  [train] fde_l: 2.972\n",
      "  [train] fde_nl: 2.870\n",
      "  [train] g_l2_loss_abs: 0.305\n",
      "  [train] g_l2_loss_rel: 0.305\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(metrics_val.items()):\n",
    "    print('  [val] {}: {:.3f}'.format(k, v))\n",
    "    checkpoint['metrics_val'][k].append(v)\n",
    "for k, v in sorted(metrics_train.items()):\n",
    "    print('  [train] {}: {:.3f}'.format(k, v))\n",
    "    checkpoint['metrics_train'][k].append(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_11_6",
   "language": "python",
   "name": "cuda_11_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
